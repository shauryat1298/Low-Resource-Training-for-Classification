{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchtext.vocab import vocab\n",
    "from torchinfo import summary\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from datasets import load_dataset, Dataset, DatasetDict\n",
    "\n",
    "from transformers import DataCollatorForTokenClassification\n",
    "import random\n",
    "\n",
    "from nltk.corpus import brown\n",
    "\n",
    "from pathlib import Path\n",
    "import os\n",
    "import sys\n",
    "from itertools import chain\n",
    "\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = Path(\"C:/Users/shaur/Desktop/Research/low_resource_training/pos_tagging\")\n",
    "artifacts_path = os.path.join(base_path, \"artifacts\")\n",
    "word2vec_model_path = os.path.join(artifacts_path, \"word2vec_model/GoogleNews-vectors-negative300.bin\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "brown_corpus = brown.tagged_sents(tagset='universal')\n",
    "tagged_sentences = brown_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [] # store input sequence\n",
    "Y = [] # store output sequence\n",
    "\n",
    "for sentence in tagged_sentences:\n",
    "    X_sentence = []\n",
    "    Y_sentence = []\n",
    "    for entity in sentence:         \n",
    "        X_sentence.append(entity[0].lower())  # entity[0] contains the word\n",
    "        Y_sentence.append(entity[1])  # entity[1] contains corresponding tag\n",
    "        \n",
    "    X.append(X_sentence)\n",
    "    Y.append(Y_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of tagged sentences: 57340\n",
      "Vocabulary size: 49815\n",
      "Total number of tags: 12\n"
     ]
    }
   ],
   "source": [
    "num_words = len(set([word.lower() for sentence in X for word in sentence]))\n",
    "num_tags   = len(set([word.lower() for sentence in Y for word in sentence]))\n",
    "\n",
    "print(\"Total number of tagged sentences: {}\".format(len(X)))\n",
    "print(\"Vocabulary size: {}\".format(num_words))\n",
    "print(\"Total number of tags: {}\".format(num_tags))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample X:  ['the', 'fulton', 'county', 'grand', 'jury', 'said', 'friday', 'an', 'investigation', 'of', \"atlanta's\", 'recent', 'primary', 'election', 'produced', '``', 'no', 'evidence', \"''\", 'that', 'any', 'irregularities', 'took', 'place', '.'] \n",
      "\n",
      "sample Y:  ['DET', 'NOUN', 'NOUN', 'ADJ', 'NOUN', 'VERB', 'NOUN', 'DET', 'NOUN', 'ADP', 'NOUN', 'ADJ', 'NOUN', 'NOUN', 'VERB', '.', 'DET', 'NOUN', '.', 'ADP', 'DET', 'NOUN', 'VERB', 'NOUN', '.'] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('sample X: ', X[0], '\\n')\n",
    "print('sample Y: ', Y[0], '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of first input sequence  : 25\n",
      "Length of first output sequence : 25\n"
     ]
    }
   ],
   "source": [
    "print(\"Length of first input sequence  : {}\".format(len(X[0])))\n",
    "print(\"Length of first output sequence : {}\".format(len(Y[0])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "brown_df = Dataset.from_dict({\n",
    "    'tokens': X,\n",
    "    'pos_tags': Y\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tokens</th>\n",
       "      <th>pos_tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[the, fulton, county, grand, jury, said, frida...</td>\n",
       "      <td>[DET, NOUN, NOUN, ADJ, NOUN, VERB, NOUN, DET, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[the, jury, further, said, in, term-end, prese...</td>\n",
       "      <td>[DET, NOUN, ADV, VERB, ADP, NOUN, NOUN, ADP, D...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[the, september-october, term, jury, had, been...</td>\n",
       "      <td>[DET, NOUN, NOUN, NOUN, VERB, VERB, VERB, ADP,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[``, only, a, relative, handful, of, such, rep...</td>\n",
       "      <td>[., ADV, DET, ADJ, NOUN, ADP, ADJ, NOUN, VERB,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[the, jury, said, it, did, find, that, many, o...</td>\n",
       "      <td>[DET, NOUN, VERB, PRON, VERB, VERB, ADP, ADJ, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              tokens  \\\n",
       "0  [the, fulton, county, grand, jury, said, frida...   \n",
       "1  [the, jury, further, said, in, term-end, prese...   \n",
       "2  [the, september-october, term, jury, had, been...   \n",
       "3  [``, only, a, relative, handful, of, such, rep...   \n",
       "4  [the, jury, said, it, did, find, that, many, o...   \n",
       "\n",
       "                                            pos_tags  \n",
       "0  [DET, NOUN, NOUN, ADJ, NOUN, VERB, NOUN, DET, ...  \n",
       "1  [DET, NOUN, ADV, VERB, ADP, NOUN, NOUN, ADP, D...  \n",
       "2  [DET, NOUN, NOUN, NOUN, VERB, VERB, VERB, ADP,...  \n",
       "3  [., ADV, DET, ADJ, NOUN, ADP, ADJ, NOUN, VERB,...  \n",
       "4  [DET, NOUN, VERB, PRON, VERB, VERB, ADP, ADJ, ...  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brown_df.set_format(type='pandas')\n",
    "df = brown_df[:]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Visualize distribution of class labels\n",
    "\n",
    "all_tags = [tag for sublist in df['pos_tags'] for tag in sublist]\n",
    "\n",
    "# Convert to a pandas Series and count occurrences of each tag\n",
    "tag_counts = pd.Series(all_tags).value_counts(ascending=True)\n",
    "\n",
    "# Plot the counts\n",
    "tag_counts.plot.barh()\n",
    "plt.xlabel('Count')\n",
    "plt.ylabel('NER Tag')\n",
    "plt.title('NER Tag Counts')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['tokens', 'pos_tags'],\n",
       "        num_rows: 1000\n",
       "    })\n",
       "    val: Dataset({\n",
       "        features: ['tokens', 'pos_tags'],\n",
       "        num_rows: 100\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brown_df.reset_format()\n",
    "brown_df = brown_df.train_test_split(test_size=0.2)\n",
    "train_split_small = brown_df['train'].shuffle(seed=42).select(range(1000))\n",
    "val_split_small = brown_df['test'].shuffle(seed=42).select(range(100))\n",
    "train_val_subset = DatasetDict({'train': train_split_small, 'val': val_split_small})\n",
    "train_val_subset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Map targets to integers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['CONJ', 'DET', 'PRT', 'VERB', 'ADV', 'X', 'ADJ', 'NUM', 'PRON', 'NOUN', '.', 'ADP']\n"
     ]
    }
   ],
   "source": [
    "class_names = list(set(chain(*brown_df['train']['pos_tags'])))\n",
    "print(class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "id2label = {}\n",
    "for id_, label_ in enumerate(class_names):\n",
    "    id2label[str(id_)] = label_\n",
    "\n",
    "label2id = {}\n",
    "for id_, label_ in enumerate(class_names):\n",
    "    label2id[label_] = id_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1000/1000 [00:00<00:00, 16033.64 examples/s]\n",
      "Map: 100%|██████████| 100/100 [00:00<00:00, 14097.08 examples/s]\n"
     ]
    }
   ],
   "source": [
    "def convert_pos_tags_to_ids(example):\n",
    "    example['pos_tags'] = [label2id[tag] for tag in example['pos_tags']]\n",
    "    return example\n",
    "\n",
    "train_val_subset = train_val_subset.map(convert_pos_tags_to_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom Dataset Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(torch.utils.data.Dataset):\n",
    "\n",
    "    def __init__(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        texts = self.X[idx]\n",
    "        labels = self.y[idx]\n",
    "        sample = (labels, texts)\n",
    "        return sample\n",
    "    \n",
    "train_dataset = CustomDataset(train_val_subset['train']['tokens'], train_val_subset['train']['pos_tags'])\n",
    "val_dataset = CustomDataset(train_val_subset['val']['tokens'], train_val_subset['val']['pos_tags'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([2, 9, 3, 11, 9, 9, 10],\n",
       " ['my', 'uncle', 'looked', 'at', 'mr.', 'gorboduc', '.'])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.__getitem__(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1718"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_vocab(dataset, min_freq=1):\n",
    "\n",
    "    counter = Counter()\n",
    "    for (_, word) in dataset:\n",
    "        counter.update(word)\n",
    "    \n",
    "    my_vocab = vocab(counter, min_freq=min_freq)\n",
    "    my_vocab.insert_token('<unk>', 0)\n",
    "    my_vocab.set_default_index(0)\n",
    "\n",
    "    return my_vocab\n",
    "\n",
    "brown_vocab = get_vocab(train_dataset, min_freq=2)\n",
    "len(brown_vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collate Function for Data Loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenizer(x, vocab):\n",
    "    return [vocab[token] for token in x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_batch_emb(batch):\n",
    "    \"\"\"\n",
    "    Collates a batch of samples into tensors of labels and texts.\n",
    "\n",
    "    Parameters:\n",
    "        batch (list): A list of tuples, each containing a label and a text.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing two tensors, one for labels and one for texts.\n",
    "    \"\"\"\n",
    "    # Unpack the batch into separate lists for labels and texts\n",
    "    labels, texts = zip(*batch)\n",
    "    \n",
    "    # Convert the list of labels into a tensor of dtype int32\n",
    "    labels = torch.cat([torch.tensor(label, dtype=torch.int64) for label in labels])\n",
    "\n",
    "    # Convert the list of texts into a tensor; each text is transformed into a list of vocabulary indices using tokenizer\n",
    "    indices = torch.cat([torch.tensor(tokenizer(text_list, brown_vocab), dtype=torch.int64) for text_list in texts])\n",
    "\n",
    "    return labels, indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "batch_size = 2\n",
    "train_loader = DataLoader(dataset=train_dataset,\n",
    "                          batch_size=batch_size,\n",
    "                          shuffle=True,\n",
    "                          collate_fn=collate_batch_emb\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 7,  3,  3,  7,  4,  4, 11,  6, 10,  9,  3,  3,  7,  4, 10]) tensor([ 78, 233, 185, 104,  58, 612,  58, 539, 184, 421,   0, 192,   2, 829,\n",
      "          4])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.0.2 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"c:\\Users\\shaur\\anaconda3\\envs\\research_env\\lib\\runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"c:\\Users\\shaur\\anaconda3\\envs\\research_env\\lib\\runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"c:\\Users\\shaur\\anaconda3\\envs\\research_env\\lib\\site-packages\\ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"c:\\Users\\shaur\\anaconda3\\envs\\research_env\\lib\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"c:\\Users\\shaur\\anaconda3\\envs\\research_env\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 739, in start\n",
      "    self.io_loop.start()\n",
      "  File \"c:\\Users\\shaur\\anaconda3\\envs\\research_env\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 215, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"c:\\Users\\shaur\\anaconda3\\envs\\research_env\\lib\\asyncio\\base_events.py\", line 596, in run_forever\n",
      "    self._run_once()\n",
      "  File \"c:\\Users\\shaur\\anaconda3\\envs\\research_env\\lib\\asyncio\\base_events.py\", line 1890, in _run_once\n",
      "    handle._run()\n",
      "  File \"c:\\Users\\shaur\\anaconda3\\envs\\research_env\\lib\\asyncio\\events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"c:\\Users\\shaur\\anaconda3\\envs\\research_env\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 545, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"c:\\Users\\shaur\\anaconda3\\envs\\research_env\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 534, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"c:\\Users\\shaur\\anaconda3\\envs\\research_env\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 437, in dispatch_shell\n",
      "    await result\n",
      "  File \"c:\\Users\\shaur\\anaconda3\\envs\\research_env\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 362, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"c:\\Users\\shaur\\anaconda3\\envs\\research_env\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 778, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"c:\\Users\\shaur\\anaconda3\\envs\\research_env\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 449, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"c:\\Users\\shaur\\anaconda3\\envs\\research_env\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"c:\\Users\\shaur\\anaconda3\\envs\\research_env\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3006, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"c:\\Users\\shaur\\anaconda3\\envs\\research_env\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3061, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"c:\\Users\\shaur\\anaconda3\\envs\\research_env\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"c:\\Users\\shaur\\anaconda3\\envs\\research_env\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3266, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"c:\\Users\\shaur\\anaconda3\\envs\\research_env\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3445, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"c:\\Users\\shaur\\anaconda3\\envs\\research_env\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3505, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\shaur\\AppData\\Local\\Temp\\ipykernel_33892\\2647315296.py\", line 3, in <module>\n",
      "    for label, text in train_loader:\n",
      "  File \"c:\\Users\\shaur\\anaconda3\\envs\\research_env\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\", line 631, in __next__\n",
      "    data = self._next_data()\n",
      "  File \"c:\\Users\\shaur\\anaconda3\\envs\\research_env\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\", line 675, in _next_data\n",
      "    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration\n",
      "  File \"c:\\Users\\shaur\\anaconda3\\envs\\research_env\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\", line 54, in fetch\n",
      "    return self.collate_fn(data)\n",
      "  File \"C:\\Users\\shaur\\AppData\\Local\\Temp\\ipykernel_33892\\1883401638.py\", line 15, in collate_batch_emb\n",
      "    labels = torch.cat([torch.tensor(label, dtype=torch.int64) for label in labels])\n",
      "  File \"C:\\Users\\shaur\\AppData\\Local\\Temp\\ipykernel_33892\\1883401638.py\", line 15, in <listcomp>\n",
      "    labels = torch.cat([torch.tensor(label, dtype=torch.int64) for label in labels])\n"
     ]
    }
   ],
   "source": [
    "# iterate over the dataloader\n",
    "torch.manual_seed(0)\n",
    "for label, text in train_loader:\n",
    "    print(label, text)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleMLP(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim1, hidden_dim2, drop_prob1, drop_prob2, num_outputs):\n",
    "        super().__init__()\n",
    "\n",
    "        # EmbeddingBag_layer->Linear->ReLU->BatchNorm->Dropout->Linear->ReLU->BatchNorm->Dropout->Linear\n",
    "\n",
    "        # Embedding layer\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "\n",
    "        # First Linear layer\n",
    "        self.linear1 = nn.Linear(embedding_dim, hidden_dim1)\n",
    "        # Batch normalization for first linear layer\n",
    "        self.batchnorm1 = nn.BatchNorm1d(num_features=hidden_dim1)\n",
    "        # Dropout for first linear layer\n",
    "        self.dropout1 = nn.Dropout(p=drop_prob1)\n",
    "\n",
    "        # Second Linear layer\n",
    "        self.linear2 = nn.Linear(hidden_dim1, hidden_dim2)\n",
    "        # Batch normalization for second linear layer\n",
    "        self.batchnorm2 = nn.BatchNorm1d(num_features=hidden_dim2)\n",
    "        # Dropout for second linear layer\n",
    "        self.dropout2 = nn.Dropout(p=drop_prob2)\n",
    "\n",
    "        # Final Linear layer\n",
    "        self.linear3 = nn.Linear(hidden_dim2, num_outputs)\n",
    "\n",
    "    def forward(self, indices):\n",
    "\n",
    "        # Pass data through the embedding layer\n",
    "        x = self.embedding(indices)\n",
    "\n",
    "        # First linear layer followed by ReLU, BatchNorm, and Dropout\n",
    "        x = self.linear1(x)\n",
    "        x = nn.ReLU()(x)\n",
    "        x = self.batchnorm1(x)\n",
    "        x = self.dropout1(x)\n",
    "\n",
    "        # Second linear layer followed by ReLU, BatchNorm, and Dropout\n",
    "        x = self.linear2(x)\n",
    "        x = nn.ReLU()(x)\n",
    "        x = self.batchnorm2(x)\n",
    "        x = self.dropout2(x)\n",
    "\n",
    "        # Final linear layer\n",
    "        x = self.linear3(x)\n",
    "\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "SimpleMLP                                [5, 12]                   --\n",
       "├─Embedding: 1-1                         [5, 200]                  343,600\n",
       "├─Linear: 1-2                            [5, 100]                  20,100\n",
       "├─BatchNorm1d: 1-3                       [5, 100]                  200\n",
       "├─Dropout: 1-4                           [5, 100]                  --\n",
       "├─Linear: 1-5                            [5, 20]                   2,020\n",
       "├─BatchNorm1d: 1-6                       [5, 20]                   40\n",
       "├─Dropout: 1-7                           [5, 20]                   --\n",
       "├─Linear: 1-8                            [5, 12]                   252\n",
       "==========================================================================================\n",
       "Total params: 366,212\n",
       "Trainable params: 366,212\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (M): 1.83\n",
       "==========================================================================================\n",
       "Input size (MB): 0.00\n",
       "Forward/backward pass size (MB): 0.02\n",
       "Params size (MB): 1.46\n",
       "Estimated Total Size (MB): 1.48\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the device\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Define the sequential model\n",
    "# this will invoke the __init__() function of the model\n",
    "model = SimpleMLP(vocab_size=len(brown_vocab) , embedding_dim=200, hidden_dim1=100, hidden_dim2=20, drop_prob1=0.5, drop_prob2=0.5, num_outputs=len(label2id))\n",
    "\n",
    "# Move the model to the device\n",
    "model = model.to(device)\n",
    "\n",
    "# Generate some dummy input data and offsets, and move them to the device\n",
    "data = torch.tensor([1, 2, 4, 5, 4], dtype = torch.int32).to(device)\n",
    "\n",
    "# Generate summary\n",
    "summary(model, input_data=data, device=device, depth =10, verbose = False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions to Train and Evaluate Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def step(inputs, targets, model, device, loss_function=None, optimizer=None):\n",
    "    \"\"\"\n",
    "    Performs a forward and backward pass for a given batch of inputs and targets.\n",
    "\n",
    "    Parameters:\n",
    "    - inputs (torch.Tensor): The input data for the model.\n",
    "    - targets (torch.Tensor): The true labels for the input data.\n",
    "    - model (torch.nn.Module): The neural network model.\n",
    "    - device (torch.device): The computing device (CPU or GPU).\n",
    "    - loss_function (torch.nn.Module, optional): The loss function to use.\n",
    "    - optimizer (torch.optim.Optimizer, optional): The optimizer to update model parameters.\n",
    "\n",
    "    Returns:\n",
    "    - loss (float): The computed loss value (only if loss_function is not None).\n",
    "    - outputs (torch.Tensor): The predictions from the model.\n",
    "    - correct (int): The number of correctly classified samples in the batch.\n",
    "    \"\"\"\n",
    "    # Move the model and data to the device\n",
    "    model = model.to(device)\n",
    "    inputs = tuple(input_tensor.to(device)\n",
    "                            for input_tensor in inputs)\n",
    "\n",
    "    targets = targets.to(device)\n",
    "\n",
    "    # Step 1: Forward pass to get the model's predictions\n",
    "    outputs = model(inputs)\n",
    "\n",
    "    # Step 2a: Compute the loss using the provided loss function\n",
    "    if loss_function:\n",
    "        loss = loss_function(outputs, targets)\n",
    "\n",
    "    # Step 2b: Calculate the number of correctly classified samples\n",
    "    predicted = torch.argmax(outputs.data, 1)\n",
    "    correct = (predicted == targets).sum().item()\n",
    "\n",
    "    # Step 3 and 4: Perform backward pass and update model parameters if an optimizer is provided\n",
    "    if optimizer:\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # Return relevant metrics\n",
    "    if loss_function:\n",
    "        return loss, outputs, correct\n",
    "    else:\n",
    "        return None, outputs, correct\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(train_loader, model, device, loss_function, optimizer):\n",
    "    \"\"\"\n",
    "    Trains the model for one epoch using the provided data loader and updates the model parameters.\n",
    "\n",
    "    Parameters:\n",
    "    - train_loader (torch.utils.data.DataLoader): DataLoader object for the training set.\n",
    "    - model (torch.nn.Module): The neural network model to be trained.\n",
    "    - device (torch.device): The computing device (CPU or GPU).\n",
    "    - loss_function (torch.nn.Module): The loss function to use for training.\n",
    "    - optimizer (torch.optim.Optimizer): The optimizer to update model parameters.\n",
    "\n",
    "    Returns:\n",
    "    - train_loss (float): Average training loss for the epoch.\n",
    "    - train_acc (float): Training accuracy for the epoch.\n",
    "    \"\"\"\n",
    "    # Set the model to training mode\n",
    "    model.train()\n",
    "\n",
    "    # Initialize variables to track running training loss and correct predictions\n",
    "    running_train_loss = 0.0\n",
    "    running_train_correct = 0\n",
    "\n",
    "    # Iterate over all batches in the training data\n",
    "    for inputs, targets in train_loader:\n",
    "        # Perform a forward and backward pass, updating model parameters\n",
    "        loss, _, correct = step(inputs, targets, model, device, loss_function, optimizer)\n",
    "\n",
    "        # Update running loss and correct predictions counter\n",
    "        running_train_loss += loss.item()\n",
    "        running_train_correct += correct\n",
    "\n",
    "    # Compute average loss and accuracy for the entire training set\n",
    "    train_loss = running_train_loss / len(train_loader)\n",
    "    train_acc = running_train_correct / len(train_loader.dataset)\n",
    "\n",
    "    return train_loss, train_acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def val_epoch(valid_loader, model, device, loss_function):\n",
    "    \"\"\"\n",
    "    Validates the model for one epoch using the provided data loader.\n",
    "\n",
    "    Parameters:\n",
    "    - valid_loader (torch.utils.data.DataLoader): DataLoader object for the validation set.\n",
    "    - model (torch.nn.Module): The neural network model to be validated.\n",
    "    - device (torch.device): The computing device (CPU or GPU).\n",
    "    - loss_function (torch.nn.Module): The loss function to evaluate the model.\n",
    "\n",
    "    Returns:\n",
    "    - val_loss (float): Average validation loss for the epoch.\n",
    "    - val_acc (float): Validation accuracy for the epoch.\n",
    "    \"\"\"\n",
    "    # Set the model to evaluation mode\n",
    "    model.eval()\n",
    "\n",
    "    # Initialize variables to track running validation loss and correct predictions\n",
    "    running_val_loss = 0.0\n",
    "    running_val_correct = 0\n",
    "\n",
    "    # Disable gradient computation\n",
    "    with torch.no_grad():\n",
    "        # Iterate over all batches in the validation data\n",
    "        for inputs, targets in valid_loader:\n",
    "            # Perform a forward pass to get loss and number of correct predictions\n",
    "            loss, _, correct = step(inputs, targets, model, device, loss_function, optimizer=None)\n",
    "\n",
    "            # Update running loss and correct predictions counter\n",
    "            running_val_loss += loss.item()\n",
    "            running_val_correct += correct\n",
    "\n",
    "    # Compute average loss and accuracy for the entire validation set\n",
    "    val_loss = running_val_loss / len(valid_loader)\n",
    "    val_acc = running_val_correct / len(valid_loader.dataset)\n",
    "\n",
    "    return val_loss, val_acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_loader, valid_loader, model, optimizer, loss_function, epochs, device):\n",
    "    \"\"\"\n",
    "    Trains and validates the model, and returns history of train and validation metrics.\n",
    "\n",
    "    Parameters:\n",
    "    - train_loader (torch.utils.data.DataLoader): DataLoader for the training set.\n",
    "    - valid_loader (torch.utils.data.DataLoader): DataLoader for the validation set.\n",
    "    - model (torch.nn.Module): Neural network model to train.\n",
    "    - optimizer (torch.optim.Optimizer): Optimizer algorithm.\n",
    "    - loss_function (torch.nn.Module): Loss function to evaluate the model.\n",
    "    - epochs (int): Number of epochs to train the model.\n",
    "    - device (torch.device): The computing device (CPU or GPU).\n",
    "\n",
    "    Returns:\n",
    "    - train_loss_history (list): History of training loss for each epoch.\n",
    "    - train_acc_history (list): History of training accuracy for each epoch.\n",
    "    - valid_loss_history (list): History of validation loss for each epoch.\n",
    "    - valid_acc_history (list): History of validation accuracy for each epoch.\n",
    "    \"\"\"\n",
    "\n",
    "    # Initialize lists to store metrics for each epoch\n",
    "    train_loss_history = []\n",
    "    valid_loss_history = []\n",
    "    train_acc_history = []\n",
    "    valid_acc_history = []\n",
    "\n",
    "    # Loop over the number of specified epochs\n",
    "    for epoch in range(epochs):\n",
    "        # Train model on training data and capture metrics\n",
    "        train_loss, train_acc = train_epoch(\n",
    "            train_loader, model, device, loss_function, optimizer)\n",
    "\n",
    "        # Validate model on validation data and capture metrics\n",
    "        valid_loss, valid_acc = val_epoch(\n",
    "            valid_loader, model, device, loss_function)\n",
    "\n",
    "        # Store metrics for this epoch\n",
    "        train_loss_history.append(train_loss)\n",
    "        train_acc_history.append(train_acc)\n",
    "        valid_loss_history.append(valid_loss)\n",
    "        valid_acc_history.append(valid_acc)\n",
    "\n",
    "        # Output epoch-level summary\n",
    "        print(f\"Epoch {epoch+1}/{epochs}\")\n",
    "        print(f\"Train Loss: {train_loss:.4f} | Train Accuracy: {train_acc*100:.2f}%\")\n",
    "        print(f\"Valid Loss: {valid_loss:.4f} | Valid Accuracy: {valid_acc*100:.2f}%\")\n",
    "        print()\n",
    "\n",
    "    return train_loss_history, train_acc_history, valid_loss_history, valid_acc_history\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model Parameters\n",
    "EMBED_DIM=512\n",
    "VOCAB_SIZE=len(brown_vocab)\n",
    "HIDDEN_DIM1=200\n",
    "HIDDEN_DIM2=100\n",
    "DROP_PROB1=0.5\n",
    "DROP_PROB2=0.5\n",
    "NUM_OUTPUTS=len(label2id)\n",
    "\n",
    "# training\n",
    "EPOCHS=5\n",
    "BATCH_SIZE=4\n",
    "LEARNING_RATE=0.001\n",
    "WEIGHT_DECAY=0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fixing the seed value for reproducibility across runs\n",
    "SEED = 2345\n",
    "random.seed(SEED)                     # Set seed for Python's 'random' module\n",
    "np.random.seed(SEED)                  # Set seed for NumPy's random number generation\n",
    "torch.manual_seed(SEED)               # Set seed for PyTorch's CPU operations\n",
    "torch.cuda.manual_seed(SEED)          # Set seed for PyTorch's CUDA (GPU) operations\n",
    "torch.backends.cudnn.deterministic = True  # Ensure deterministic behavior in CuDNN\n",
    "\n",
    "# Define collate function with a fixed vocabulary using the 'partial' function\n",
    "collate_fn = collate_batch_emb\n",
    "\n",
    "# Data Loaders for training, validation, and test sets\n",
    "# These loaders handle batching, shuffling, and data processing using the custom collate function\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size = BATCH_SIZE, shuffle=True,\n",
    "                                           collate_fn=collate_fn)\n",
    "valid_loader = torch.utils.data.DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False,\n",
    "                                           collate_fn=collate_fn)\n",
    "\n",
    "# Define the loss function for the model, using cross-entropy loss\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "\n",
    "# Define the model with specified hyperparameters\n",
    "model_brown = SimpleMLP(vocab_size=VOCAB_SIZE,\n",
    "                       embedding_dim=EMBED_DIM,\n",
    "                       hidden_dim1=HIDDEN_DIM1,\n",
    "                       hidden_dim2=HIDDEN_DIM2,\n",
    "                       drop_prob1=DROP_PROB1,\n",
    "                       drop_prob2=DROP_PROB2,\n",
    "                       num_outputs=NUM_OUTPUTS)\n",
    "\n",
    "# Initialize the optimizer for training, using AdamW optimizer with specified learning rate\n",
    "optimizer = torch.optim.AdamW(model_brown.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "# Define the device for model training (use CUDA if available, else CPU)\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Im here\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "embedding(): argument 'indices' (position 2) must be Tensor, not tuple",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[31], line 10\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIm here\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():  \u001b[38;5;66;03m# Ensure no gradients are calculated since this is evaluation.\u001b[39;00m\n\u001b[1;32m---> 10\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmodel_imdb\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     11\u001b[0m     loss \u001b[38;5;241m=\u001b[39m loss_function(output, targets)\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mActual loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mloss\u001b[38;5;241m.\u001b[39mitem()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\shaur\\anaconda3\\envs\\research_env\\lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\shaur\\anaconda3\\envs\\research_env\\lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[22], line 30\u001b[0m, in \u001b[0;36mSimpleMLP.forward\u001b[1;34m(self, indices)\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, indices):\n\u001b[0;32m     28\u001b[0m \n\u001b[0;32m     29\u001b[0m     \u001b[38;5;66;03m# Pass data through the embedding layer\u001b[39;00m\n\u001b[1;32m---> 30\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindices\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     32\u001b[0m     \u001b[38;5;66;03m# First linear layer followed by ReLU, BatchNorm, and Dropout\u001b[39;00m\n\u001b[0;32m     33\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlinear1(x)\n",
      "File \u001b[1;32mc:\\Users\\shaur\\anaconda3\\envs\\research_env\\lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\shaur\\anaconda3\\envs\\research_env\\lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\shaur\\anaconda3\\envs\\research_env\\lib\\site-packages\\torch\\nn\\modules\\sparse.py:163\u001b[0m, in \u001b[0;36mEmbedding.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    162\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 163\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    164\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_norm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    165\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnorm_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscale_grad_by_freq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msparse\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\shaur\\anaconda3\\envs\\research_env\\lib\\site-packages\\torch\\nn\\functional.py:2264\u001b[0m, in \u001b[0;36membedding\u001b[1;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[0;32m   2258\u001b[0m     \u001b[38;5;66;03m# Note [embedding_renorm set_grad_enabled]\u001b[39;00m\n\u001b[0;32m   2259\u001b[0m     \u001b[38;5;66;03m# XXX: equivalent to\u001b[39;00m\n\u001b[0;32m   2260\u001b[0m     \u001b[38;5;66;03m# with torch.no_grad():\u001b[39;00m\n\u001b[0;32m   2261\u001b[0m     \u001b[38;5;66;03m#   torch.embedding_renorm_\u001b[39;00m\n\u001b[0;32m   2262\u001b[0m     \u001b[38;5;66;03m# remove once script supports set_grad_enabled\u001b[39;00m\n\u001b[0;32m   2263\u001b[0m     _no_grad_embedding_renorm_(weight, \u001b[38;5;28minput\u001b[39m, max_norm, norm_type)\n\u001b[1;32m-> 2264\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscale_grad_by_freq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msparse\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mTypeError\u001b[0m: embedding(): argument 'indices' (position 2) must be Tensor, not tuple"
     ]
    }
   ],
   "source": [
    "for inputs, targets in train_loader:\n",
    "    # Move inputs and targets to the CPU.\n",
    "    inputs = tuple(input_tensor.to(device) for input_tensor in inputs)\n",
    "    targets = targets.to(device)\n",
    "    model_imdb = model_brown.to(device)\n",
    "    model_imdb.eval()\n",
    "    # Forward pass\n",
    "    print(\"Im here\")\n",
    "    with torch.no_grad():  # Ensure no gradients are calculated since this is evaluation.\n",
    "        output = model_imdb(inputs)\n",
    "        loss = loss_function(output, targets)\n",
    "        print(f'Actual loss: {loss.item()}')\n",
    "    break\n",
    "\n",
    "print(f'Expected Theoretical loss: {np.log(2)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "res_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
